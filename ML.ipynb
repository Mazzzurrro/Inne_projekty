{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "71f9f125",
   "metadata": {},
   "source": [
    "# KLASYFIKACJA SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "f5bb6010",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neg: 606 Pos: 76\n",
      "ACCTRAIN/ACCTEST/ROCTRAIN/ROCTEST\n",
      "0.6483669724770642 0.6745608465608466 0.7943044207706589 0.694828310456773\n",
      "SPECIFITYTRAIN/SPECIFITYTEST/SENSITIVITYTRAIN/SENSITIVITYTEST\n",
      "0.6523328459519362 0.6310090396188889 0.9362759955893817 0.7586475812946568\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "acctrain=[]\n",
    "acctest=[]\n",
    "roctrain=[]\n",
    "roctest=[]\n",
    "specifitylist=[]\n",
    "specifity1list=[]\n",
    "sensitivitylist=[]\n",
    "sensitivity1list=[]\n",
    "\n",
    "danesas=pd.read_csv('danesasowe.csv',delimiter=';',decimal=',')\n",
    "danesas['datazalozenia'] = pd.to_datetime(danesas['datazalozenia'],format='%d.%m.%Y')\n",
    "danesas['dataurodzenia'] = pd.to_datetime(danesas['dataurodzenia'],format='%d.%m.%Y')\n",
    "danesas['datapozyczki'] = pd.to_datetime(danesas['datapozyczki'],format='%d.%m.%Y')\n",
    "X=danesas.drop(['account_id','datazalozenia','dataurodzenia','datazalozenia','datapozyczki','status','disp_id','typkarty','Czy_problemy','duration','payments','balance'],axis=1)\n",
    "y=danesas['Czy_problemy']\n",
    "kolumnyX=[\"platnosci\",\"wielkosckredytu\",\"ileremittancetoanotherbank\",\"ilewithdraw\",\"ilecollectionfromanotherbank\",\"iletransakcji\",\"staz_pozyczka\",\"ilecreditcardwithdrawal\",\"A14\",\"A7\",\"POM1\",\"A9\",\"A11\",\"A16\",\"A15\",\"A4\",\"czastrwaniakredytu\",\"A12\",\"plec\",\"ilecreditincash\",\"A6\",\"A13\",\"stan_konta_przydzielanie_kredytu\",\"ilecredit\",\"A8\",\"POM2\",\"A5\",\"wiek_pozyczka\",\"A10\"]\n",
    "A=X[[\"platnosci\",\"wielkosckredytu\",\"ileremittancetoanotherbank\",\"ilewithdraw\",\"ilecollectionfromanotherbank\"]]\n",
    "neg, pos = np.bincount(y)\n",
    "print(\"Neg:\",neg,\"Pos:\",pos)\n",
    "\n",
    "for i in range(100):\n",
    "    X_train,X_test,y_train,y_test = train_test_split(A,y,test_size=0.2) \n",
    "    sc=StandardScaler()\n",
    "    X_train=sc.fit_transform(X_train)\n",
    "    X_test=sc.transform(X_test)\n",
    "    \n",
    "    clf=svm.SVC(kernel='rbf',class_weight={0:1,1:9})\n",
    "    scores = cross_val_score(clf, X_train, y_train, cv=5)\n",
    "    scores1= cross_val_score(clf, X_test, y_test, cv=5)\n",
    "    clf.fit(X_train,y_train)\n",
    "\n",
    "    #print(\"On train: %0.2f accuracy with a standard deviation of %0.2f\" % (scores.mean(), scores.std()))\n",
    "    #print(\"On test: %0.2f accuracy with a standard deviation of %0.2f\" % (scores1.mean(), scores1.std()))\n",
    "\n",
    "    y_pred=clf.predict(X_train)\n",
    "    y_pred\n",
    "    #print(\"Accuracy treningowy:\",metrics.accuracy_score(y_train, y_pred))\n",
    "\n",
    "    tn, fp, fn, tp = confusion_matrix(y_train, y_pred).ravel()\n",
    "    specificity = tn / (tn+fp)\n",
    "    sensitivity=tp/(tp+fn)\n",
    "    specificity\n",
    "\n",
    "    y_pred1=clf.predict(X_test)\n",
    "    y_pred1\n",
    "\n",
    "    #print(\"Accuracy testowy:\",metrics.accuracy_score(y_test, y_pred1))\n",
    "    tn1, fp1, fn1, tp1 = confusion_matrix(y_test, y_pred1).ravel()\n",
    "    specificity1 = tn1 / (tn1+fp1) # True negative rate\n",
    "    sensitivity1=tp1/(tp1+fn1) #True positive rate\n",
    "    sensitivity1\n",
    "\n",
    "    #### FUNKCJA ROC ####\n",
    "    acctrain.append(scores.mean())\n",
    "    acctest.append(scores1.mean())\n",
    "    roctest.append(roc_auc_score(y_test,y_pred1))\n",
    "    roctrain.append(roc_auc_score(y_train,y_pred))\n",
    "\n",
    "    specifitylist.append(specificity)\n",
    "    specifity1list.append(specificity1)\n",
    "    sensitivitylist.append(sensitivity)\n",
    "    sensitivity1list.append(sensitivity1)\n",
    "\n",
    "print(\"ACCTRAIN/ACCTEST/ROCTRAIN/ROCTEST\")\n",
    "print(np.mean(acctrain),np.mean(acctest),np.mean(roctrain),np.mean(roctest))\n",
    "print(\"SPECIFITYTRAIN/SPECIFITYTEST/SENSITIVITYTRAIN/SENSITIVITYTEST\")\n",
    "print(np.mean(specifitylist),np.mean(specifity1list),np.mean(sensitivitylist),np.mean(sensitivity1list))\n",
    "print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ddb482a",
   "metadata": {},
   "source": [
    "# KLASYFIKACJA LOGISTYCZNA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "c761dc19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neg: 606 Pos: 76\n",
      "ACCTRAIN/ACCTEST/ROCTRAIN/ROCTEST\n",
      "0.6088349993336 0.5943478260869566 0.7423719569396711 0.6346697237228058\n",
      "SPECIFITYTRAIN/SPECIFITYTEST/SENSITIVITYTRAIN/SENSITIVITYTEST\n",
      "0.5979163190748391 0.5856457245018887 0.8868275948045035 0.6836937229437229\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "acctrain=[]\n",
    "acctest=[]\n",
    "roctrain=[]\n",
    "roctest=[]\n",
    "specifitylist=[]\n",
    "specifity1list=[]\n",
    "sensitivitylist=[]\n",
    "sensitivity1list=[]\n",
    "\n",
    "danesas=pd.read_csv('danesasowe.csv',delimiter=';',decimal=',')\n",
    "danesas['datazalozenia'] = pd.to_datetime(danesas['datazalozenia'],format='%d.%m.%Y')\n",
    "danesas['dataurodzenia'] = pd.to_datetime(danesas['dataurodzenia'],format='%d.%m.%Y')\n",
    "danesas['datapozyczki'] = pd.to_datetime(danesas['datapozyczki'],format='%d.%m.%Y')\n",
    "X=danesas.drop(['account_id','datazalozenia','dataurodzenia','datazalozenia','datapozyczki','status','disp_id','typkarty','Czy_problemy','duration','payments','balance'],axis=1)\n",
    "y=danesas['Czy_problemy']\n",
    "kolumnyX=[\"platnosci\",\"wielkosckredytu\",\"ileremittancetoanotherbank\",\"ilewithdraw\",\"ilecollectionfromanotherbank\",\"iletransakcji\",\"staz_pozyczka\",\"ilecreditcardwithdrawal\",\"A14\",\"A7\",\"POM1\",\"A9\",\"A11\",\"A16\",\"A15\",\"A4\",\"czastrwaniakredytu\",\"A12\",\"plec\",\"ilecreditincash\",\"A6\",\"A13\",\"stan_konta_przydzielanie_kredytu\",\"ilecredit\",\"A8\",\"POM2\",\"A5\",\"wiek_pozyczka\",\"A10\"]\n",
    "#A=X[[\"platnosci\",\"wielkosckredytu\",\"ileremittancetoanotherbank\",\"ilewithdraw\",\"ilecollectionfromanotherbank\",\"iletransakcji\",\"staz_pozyczka\",\"ilecreditcardwithdrawal\",\"A14\",\"A7\"]]\n",
    "A=X\n",
    "neg, pos = np.bincount(y)\n",
    "print(\"Neg:\",neg,\"Pos:\",pos)\n",
    "\n",
    "for i in range(100):\n",
    "    X_train,X_test,y_train,y_test = train_test_split(A,y,test_size=0.1)\n",
    "    sc=StandardScaler()\n",
    "    X_train=sc.fit_transform(X_train)\n",
    "    X_test=sc.transform(X_test)\n",
    "    classweight={0:1,1:13}\n",
    "    clf = LogisticRegression(class_weight=classweight,max_iter=1000)\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred=clf.predict(X_train)\n",
    "    y_pred\n",
    "    \n",
    "    params={'class_weight': classweight}\n",
    "    scores = cross_val_score(clf, X_train, y_train, cv=5)\n",
    "    \n",
    "    #print(\"CV mean:\",scores.mean())\n",
    "    #print(\"Accuracy treningowy:\",metrics.accuracy_score(y_train, y_pred))\n",
    "\n",
    "    tn, fp, fn, tp = confusion_matrix(y_train, y_pred).ravel()\n",
    "    specificity = tn / (tn+fp)\n",
    "    sensitivity=tp/(tp+fn)\n",
    "    specificity\n",
    "\n",
    "    y_pred1=clf.predict(X_test)\n",
    "    y_pred1\n",
    "\n",
    "    #print(\"Accuracy testowy:\",metrics.accuracy_score(y_test, y_pred1))\n",
    "    tn1, fp1, fn1, tp1 = confusion_matrix(y_test, y_pred1).ravel()\n",
    "    specificity1 = tn1 / (tn1+fp1) # True negative rate\n",
    "    sensitivity1=tp1/(tp1+fn1) #True positive rate\n",
    "    sensitivity1\n",
    "\n",
    "    #### FUNKCJA ROC ####\n",
    "    acctrain.append(scores.mean())\n",
    "    acctest.append(metrics.accuracy_score(y_test,y_pred1))\n",
    "    roctest.append(roc_auc_score(y_test,y_pred1))\n",
    "    roctrain.append(roc_auc_score(y_train,y_pred))\n",
    "\n",
    "    specifitylist.append(specificity)\n",
    "    specifity1list.append(specificity1)\n",
    "    sensitivitylist.append(sensitivity)\n",
    "    sensitivity1list.append(sensitivity1)\n",
    "\n",
    "print(\"ACCTRAIN/ACCTEST/ROCTRAIN/ROCTEST\")\n",
    "print(np.mean(acctrain),np.mean(acctest),np.mean(roctrain),np.mean(roctest))\n",
    "print(\"SPECIFITYTRAIN/SPECIFITYTEST/SENSITIVITYTRAIN/SENSITIVITYTEST\")\n",
    "print(np.mean(specifitylist),np.mean(specifity1list),np.mean(sensitivitylist),np.mean(sensitivity1list))\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31fdf649",
   "metadata": {},
   "source": [
    "# KLASYFIKACJA GRADIENT BOOSTING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "f2d4cb4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neg: 606 Pos: 76\n",
      "ACCTRAIN/ACCTEST/ROCTRAIN/ROCTEST\n",
      "0.7050639744102358 0.6782608695652175 0.8280795256840412 0.6973443328781601\n",
      "SPECIFITYTRAIN/SPECIFITYTEST/SENSITIVITYTRAIN/SENSITIVITYTEST\n",
      "0.7068381063992423 0.6719749905426448 0.94932094496884 0.7227136752136751\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.cluster import KMeans\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from matplotlib import pyplot\n",
    "import sklearn.metrics\n",
    "\n",
    "acctrain=[]\n",
    "acctest=[]\n",
    "roctrain=[]\n",
    "roctest=[]\n",
    "specifitylist=[]\n",
    "specifity1list=[]\n",
    "sensitivitylist=[]\n",
    "sensitivity1list=[]\n",
    "\n",
    "danesas=pd.read_csv('danesasowe.csv',delimiter=';',decimal=',')\n",
    "danesas['datazalozenia'] = pd.to_datetime(danesas['datazalozenia'],format='%d.%m.%Y')\n",
    "danesas['dataurodzenia'] = pd.to_datetime(danesas['dataurodzenia'],format='%d.%m.%Y')\n",
    "danesas['datapozyczki'] = pd.to_datetime(danesas['datapozyczki'],format='%d.%m.%Y')\n",
    "X=danesas.drop(['account_id','datazalozenia','dataurodzenia','datazalozenia','datapozyczki','status','disp_id','typkarty','Czy_problemy','duration','payments','balance'],axis=1)\n",
    "y=danesas['Czy_problemy']\n",
    "kolumnyX=[\"platnosci\",\"wielkosckredytu\",\"ileremittancetoanotherbank\",\"ilewithdraw\",\"ilecollectionfromanotherbank\",\"iletransakcji\",\"staz_pozyczka\",\"ilecreditcardwithdrawal\",\"A14\",\"A7\",\"POM1\",\"A9\",\"A11\",\"A16\",\"A15\",\"A4\",\"czastrwaniakredytu\",\"A12\",\"plec\",\"ilecreditincash\",\"A6\",\"A13\",\"stan_konta_przydzielanie_kredytu\",\"ilecredit\",\"A8\",\"POM2\",\"A5\",\"wiek_pozyczka\",\"A10\"]\n",
    "A=X[[\"platnosci\",\"wielkosckredytu\",\"ileremittancetoanotherbank\",\"ilewithdraw\",\"ilecollectionfromanotherbank\"]]\n",
    "neg, pos = np.bincount(y)\n",
    "print(\"Neg:\",neg,\"Pos:\",pos)\n",
    "\n",
    "for i in range(20):\n",
    "    X_train,X_test,y_train,y_test = train_test_split(A,y,test_size=0.1)\n",
    "    sc=StandardScaler()\n",
    "    X_train=sc.fit_transform(X_train)\n",
    "    X_test=sc.transform(X_test)\n",
    "    sample_weights = np.zeros(len(y_train))\n",
    "    sample_weights[y_train == 0] = 1\n",
    "    sample_weights[y_train == 1] = 9\n",
    "    \n",
    "    \n",
    "    clf=GradientBoostingClassifier(loss='deviance',n_estimators=200,learning_rate=0.01)\n",
    "    clf.fit(X_train,y_train,sample_weight=sample_weights)   \n",
    "    y_pred=clf.predict(X_train)\n",
    "\n",
    "    params={'sample_weight': sample_weights}\n",
    "    \n",
    "    scores = cross_val_score(clf, X_train, y_train, cv=5,fit_params=params)\n",
    "\n",
    "    tn, fp, fn, tp = confusion_matrix(y_train, y_pred).ravel()\n",
    "    specificity = tn / (tn+fp)\n",
    "    sensitivity=tp/(tp+fn)\n",
    "\n",
    "    y_pred1=clf.predict(X_test)\n",
    "\n",
    "    tn1, fp1, fn1, tp1 = confusion_matrix(y_test, y_pred1).ravel()\n",
    "    specificity1 = tn1 / (tn1+fp1) # True negative rate\n",
    "    sensitivity1=tp1/(tp1+fn1) #True positive rate\n",
    "\n",
    "\n",
    "    #### FUNKCJA ROC ####\n",
    "    acctrain.append(scores.mean())\n",
    "    acctest.append(metrics.accuracy_score(y_test, y_pred1))\n",
    "    roctest.append(roc_auc_score(y_test,y_pred1))\n",
    "    roctrain.append(roc_auc_score(y_train,y_pred))\n",
    "\n",
    "    specifitylist.append(specificity)\n",
    "    specifity1list.append(specificity1)\n",
    "    sensitivitylist.append(sensitivity)\n",
    "    sensitivity1list.append(sensitivity1)\n",
    "\n",
    "print(\"ACCTRAIN/ACCTEST/ROCTRAIN/ROCTEST\")\n",
    "print(np.mean(acctrain),np.mean(acctest),np.mean(roctrain),np.mean(roctest))\n",
    "print(\"SPECIFITYTRAIN/SPECIFITYTEST/SENSITIVITYTRAIN/SENSITIVITYTEST\")\n",
    "print(np.mean(specifitylist),np.mean(specifity1list),np.mean(sensitivitylist),np.mean(sensitivity1list))\n",
    "print()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "826990a1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a08b9543",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
